# Attention

## 1. Introduction to Attention Mechanism

### 1.1 Overview of Attention in Transformers
- **Attention as the Core Component:** The lecture begins by introducing attention as the fundamental building block of the transformer architecture, a cutting-edge deep learning model.
- **Comparison to Convolution:** Attention is likened to convolution, a common operation in image processing, but is described as less structured and not constrained to fixed-size inputs. While convolution excels at processing structured inputs like images, attention is designed to handle less structured or unstructured inputs, such as language.

### 1.2 Motivation: Challenges with Language Inputs
- **Messiness of Language:** Language inputs are inherently messy and variable in structure, unlike images which have a fixed resolution or predictable structure.
- **Syntax Trees:** One traditional approach to understanding language is constructing syntax trees, which group words based on joint meaning. However, syntax trees are not universal, are difficult to build accurately, and are not an ideal foundation for modeling language in deep learning systems.
- **Need for Flexibility:** Instead of relying on rigid structures like syntax trees, the lecture emphasizes the need for a flexible operation that can process language as a flat sequence of elements (e.g., characters, words, or subword units).

## 2. Defining the Attention Operation

### 2.1 Attention as a Set Operator
- **Basic Concept:** Attention is introduced as a set operator that processes a set of feature vectors, where each vector represents an element in the input sequence (e.g., a word in a sentence).
- **Purpose of Attention:** The attention mechanism "reasons" over the set of vectors, exchanging information between them to create a more powerful representation of the input in the next layer.

### 2.2 Components of Attention: Queries, Keys, and Values
- **Splitting Inputs into Three Parts:** The attention mechanism splits the input into three distinct components:
  - **Values ($V$):** Represent the "meaning" of each input element (e.g., a word). Initially, keys and values can be considered the same, but they are later distinguished.
  - **Keys ($K$):** Serve as a different projection of the meaning of each input element, used to determine relevance or similarity.
  - **Queries ($Q$):** Act as probes that seek information from the keys and their associated values.
- **Database Analogy:** The concept of attention is compared to database retrieval, where keys are matched to retrieve associated values, but in a continuous, weighted manner rather than discrete lookups.

### 2.3 How Attention Works: Step-by-Step Process
- **Step 1: Measuring Similarity (Distance):**
  - A query ($Q$) measures its "distance" to all keys ($K$) using a similarity metric.
  - The lecture specifies the use of cosine distance, implemented as the dot product between the query and key vectors, normalized by the vector lengths.
  - Mathematically, for a query $q$ and a key $k_i$, the similarity score is computed as:
    $s_i = \frac{q \cdot k_i}{\sqrt{|q||k_i|}}$
  - This normalization by vector length is noted as a practical trick to improve performance.
- **Step 2: Exponentiation and Normalization (Softmax):**
  - The similarity scores are exponentiated to ensure positivity and then normalized using the softmax function to produce a set of weights $\alpha_i$.
  - For a set of $N$ keys, the weights are computed as:
    $\alpha_i = \frac{\exp(s_i)}{\sum_{j=1}^N \exp(s_j)}$
  - These weights $\alpha_i$ are always positive and sum to 1, resembling probabilities.
- **Step 3: Weighted Average of Values:**
  - The attention mechanism computes a weighted average of the values ($V$), where the weights are the $\alpha_i$ from the softmax.
  - For a query $q$, the output of attention is:
    $o = \sum_{i=1}^N \alpha_i v_i$
  - If a key is "close" to the query (high similarity), its corresponding value has a high weight; if the similarity is low (dot product near zero or negative), the value has little to no impact.

### 2.4 Matrix Formulation of Attention
- **Generalizing to Multiple Queries:** In practice, attention is applied to multiple queries simultaneously, not just one. This is expressed as a matrix operation for efficiency.
- **Matrix Inputs and Outputs:**
  - **Values ($V$):** A matrix of shape $N \times C$, where $N$ is the number of elements in the sequence and $C$ is the dimensionality of each value vector.
  - **Keys ($K$):** A matrix of shape $N \times C$, typically with the same dimensionality as values for simplicity.
  - **Queries ($Q$):** A matrix of shape $M \times C$, where $M$ is the number of queries (which may differ from $N$ in some cases).
- **Attention Computation in Matrix Form:**
  - Compute the similarity scores as a matrix of dot products: $S = Q K^T$.
  - Normalize by the dimensionality of the vectors: $S = \frac{Q K^T}{\sqrt{C}}$ (this scaling is a common practice in transformers to prevent large values).
  - Apply softmax to normalize the scores row-wise (for each query): $A = \text{softmax}(S)$.
  - Compute the output as a weighted sum of values: $O = A V$.
  - The output $O$ is a matrix of shape $M \times C$, where each row corresponds to the attention output for a query.
- **Flexibility in Dimensionality:** While $C$ is typically the same for $Q$, $K$, and $V$ in practice (for simplicity), it is theoretically possible to use different dimensionalities (e.g., $C_1$ for keys and $C_2$ for values), which would result in an output dimensionality of $C_2$.

### 2.5 Properties of Attention
- **General Operator:** Attention is described as a highly general operator capable of modeling arbitrary interactions within sequences, making it suitable for tasks where the relationships between elements are not fixed or structured.

## 3. Preparing Inputs for Attention

### 3.1 Splitting Sequences
- **Breaking Down Language Inputs:** To apply attention to language, the input sentence must first be split into a sequence of elements. Three approaches are discussed:
  - **Characters:** Splitting into characters results in a very long sequence, with each element having a limited vocabulary (e.g., 256 possible values for ASCII characters). This approach is computationally expensive due to the sequence length.
  - **Words:** Splitting into words creates a more compact sequence, but the vocabulary size can be very large, especially in languages with rich morphology, leading to a large number of possible elements.
  - **Tokenization (Subword Units):** A middle ground, often used in practice, is tokenization, which splits sentences into subword units or parts of words. This balances sequence length and vocabulary size, making it the standard approach in modern language models.

### 3.2 Embedding Inputs
- **What is Embedding?** Each element in the sequence (e.g., word, character, or token) is converted into a feature vector through an embedding process.
  - An embedding associates a specific input element with a fixed-size vector of numbers, representing its "meaning" in a continuous space.
  - For example, the word "my" might be embedded as $[1, 0, 1]$, and "kid" as $[0, 5, 0]$. If "my" appears again, it receives the same embedding vector.
- **Purpose of Embedding:** Embeddings translate discrete inputs (words, tokens) into a format that neural networks can process, enabling the network to learn relationships between elements based on their vector representations.

### 3.3 Feeding Embeddings into Attention
- **Initial Setup for Attention:** The embedded feature vectors are directly used as the queries ($Q$), keys ($K$), and values ($V$) in the attention mechanism.
  - This setup allows the attention mechanism to learn how to "mix" or relate these vectors, capturing dependencies and relationships within the sequence.
- **Process Summary:**
  1. Split the sentence into elementary units (e.g., tokens).
  2. Embed each unit into a feature vector.
  3. Feed the embedded vectors into the attention mechanism, setting $Q = K = V = X$, where $X$ is the matrix of embedded vectors.

## 4. Types of Attention Mechanisms

### 4.1 Self-Attention
- **Definition:** Self-attention occurs when the queries, keys, and values all come from the same input sequence, i.e., $Q = K = V = X$.
  - In this case, the attention mechanism learns to relate elements within the same sequence to each other.
- **Applications:** Self-attention is heavily used in natural language processing tasks, such as language modeling, where the goal is to understand relationships within a single sentence or document.
- **Properties:** In self-attention, the number of elements in $Q$, $K$, and $V$ is the same (i.e., $M = N$).

### 4.2 Cross-Attention
- **Definition:** Cross-attention occurs when the queries come from a different input sequence than the keys and values, i.e., $K = V = X$ (from one input) and $Q = Z$ (from another input).
  - This setup allows the attention mechanism to relate elements from one set (e.g., a sentence) to elements in another set (e.g., an image or another sentence).
- **Applications:** Cross-attention is widely used in tasks that involve multiple modalities or inputs, such as:
  - **Advanced Computer Vision:** In object detection, cross-attention transforms image features into object detections (e.g., bounding boxes) by having queries attend to image features.
  - **Vision-Language Tasks:** In models like CLIP or DALL-E, cross-attention enables a language model to attend to visual inputs, or vice versa, allowing tasks like image captioning or text-to-image generation.
- **Properties:** In cross-attention, the number of elements in $Q$ (denoted $M$) can differ from the number of elements in $K$ and $V$ (denoted $N$).

### 4.3 Key Difference Between Self-Attention and Cross-Attention
- **Input Source:** The primary difference is whether the queries, keys, and values come from the same input sequence (self-attention) or different sequences (cross-attention).
  - Self-attention: $Q$, $K$, and $V$ have the same number of elements ($M = N$).
  - Cross-attention: $Q$ can have a different number of elements ($M \neq N$), while $K$ and $V$ have the same number of elements ($N$).

## 5. Properties and Advantages of Attention

### 5.1 Flexibility as a Set Operator
- **Set-Based Reasoning:** Attention is described as a "set operator," meaning it operates on a set of elements (feature vectors) without regard to their order or the size of the set.
  - This property makes attention highly flexible, as it can handle sequences of arbitrary length, unlike convolution, which is constrained by fixed kernel sizes.
- **Relating Elements:** Attention allows the network to learn arbitrary relationships between elements in the set, making it ideal for tasks where dependencies are not local or fixed (e.g., long-range dependencies in language).

### 5.2 Summary of Inputs and Outputs
- **Inputs to Attention:** Attention takes three inputs:
  - Queries ($Q$): Probes seeking information.
  - Keys ($K$): Elements to be matched against.
  - Values ($V$): Elements to be retrieved based on matches.
- **Output of Attention:** The output is a new set of vectors, where each vector is a weighted combination of the values, with weights determined by the similarity between queries and keys.
- **Self-Attention vs. Cross-Attention:** The distinction depends on whether $Q$, $K$, and $V$ come from the same set (self-attention) or different sets (cross-attention).

## 6. Additional Details (Added for Context)

### 6.1 Scaled Dot-Product Attention
- **Practical Implementation:** The lecture describes a specific form of attention known as "scaled dot-product attention," which is the standard in transformer models (e.g., as introduced in the seminal paper "Attention is All You Need" by Vaswani et al., 2017).
- **Scaling Factor:** The normalization by $\sqrt{C}$ in the similarity score computation ($S = \frac{Q K^T}{\sqrt{C}}$) is crucial to prevent the dot products from growing too large, especially when the dimensionality $C$ is high. This scaling stabilizes training by keeping the softmax gradients manageable.

### 6.2 Multi-Head Attention
- **Extension of Attention:** While not explicitly mentioned in the transcript, it is worth noting that in practice, transformers use "multi-head attention," where the attention mechanism is applied multiple times in parallel (with different learned projections of $Q$, $K$, and $V$) and the results are concatenated. This allows the model to attend to different aspects or relationships in the input simultaneously.
  - Mathematically, if there are $H$ heads, the output of multi-head attention is:
    $\text{MultiHead}(Q, K, V) = \text{Concat}(\text{head}_1, \text{head}_2, \dots, \text{head}_H) W^O$
    where $\text{head}_i = \text{Attention}(Q W_i^Q, K W_i^K, V W_i^V)$, and $W_i^Q$, $W_i^K$, $W_i^V$, and $W^O$ are learned projection matrices.

### 6.3 Positional Encoding
- **Handling Order in Sequences:** The lecture does not discuss positional encoding, but it is a critical component in transformers for language tasks. Since attention treats inputs as a set (ignoring order), transformers add positional encodings to the embedded vectors to encode the position of each element in the sequence. This allows the model to distinguish between "the dog chased the cat" and "the cat chased the dog."

### 6.4 Computational Complexity
- **Efficiency Considerations:** Attention, especially self-attention, has a computational complexity of $O(N^2 \cdot C)$ for a sequence of length $N$ and dimensionality $C$, due to the computation of the $N \times N$ similarity matrix. This can be a bottleneck for very long sequences, leading to the development of efficient variants like sparse attention or low-rank approximations (e.g., in models like Performer or Linformer).

## 7. Conclusion
- **Summary of Attention:** The lecture concludes by reiterating that attention is a powerful, flexible set operator that enables deep networks to reason over sets of elements, relate them to one another, and handle sequences of arbitrary length.
- **Role in Transformers:** Attention is the cornerstone of the transformer architecture, replacing traditional recurrent and convolutional layers in many tasks, particularly in natural language processing and beyond.
- **Key Takeaways:**
  - Attention processes sequences by splitting inputs into queries, keys, and values, computing similarities, and producing weighted averages.
  - Self-attention is used for tasks within a single sequence, while cross-attention is used for tasks involving multiple sequences or modalities.
  - The flexibility and generality of attention make it a cornerstone of modern deep learning models.
