# Introduction to Generative Models

## A) Discriminative Models

### **Definition**:
Discriminative models focus on learning the decision boundary between different classes by directly modeling the conditional probability \( $P(Y|X)$ \).

### **Objective Function**:
- The goal is to **maximize** the likelihood of the correct label given the input.
- For classification tasks: $P(y | x) = c_y^T f(x)$
- For regression tasks: $P(y | x) = \mathcal{N}(y; \mu(x), \sigma(x))$

### **Examples**:
- Logistic Regression
- Support Vector Machines (SVMs)
- Neural Networks for classification
- Random Forests
- Conditional Random Fields (CRFs)

---

## B) Generative Models

### **Definition**:
Generative models aim to **learn the distribution of data** \( $P(X)$ \) rather than just the decision boundary.

### **Objective Function**:
- Instead of predicting $y \text{ given } x$, generative models focus on estimating the probability density \( $P(X)$ \).
- The challenge is to ensure that: $\sum_x P(x) = 1 \quad \forall x$
- This is often **impossible to compute exactly**.

### **Examples**:
- Gaussian Mixture Models (GMMs)
- Hidden Markov Models (HMMs)
- Variational Autoencoders (VAEs)
- Generative Adversarial Networks (GANs)
- Normalizing Flows
- Diffusion Models

---

## C) Two Tasks of Generative Models

1. **Density Estimation**:
   - The model learns an explicit function for \( $P(X)$ \).
   - Example: Variational Inference in VAEs.

2. **Sampling**:
   - The model generates new samples \( $x \sim P(X)$ \).
   - Example: GANs and Diffusion Models.

---

## D) Why Both Tasks are Hard

### **1. Density Estimation is Computationally Expensive**
- Computing the full probability distribution over high-dimensional data is **infeasible**.
- Approximate methods like **Variational Inference** or **Monte Carlo Sampling** are used.

### **2. Sampling is Challenging**
- Directly drawing samples from \( $P(X)$ \) is difficult.
- Many methods require a transformation of noise \( $z \sim P(Z)$ \) into meaningful samples.
- GANs use a discriminator network to improve sample quality.
- Diffusion models iteratively refine samples over time.

---

## E) Comparison of Generative and Discriminative Models

| Feature             | Generative Models       | Discriminative Models    |
|---------------------|------------------------|--------------------------|
| **Definition**      | Learns full data distribution \( $P(X)$ \) | Learns decision boundary \( $P(Y|X)$ \) |
| **Objective**      | Density estimation and sampling | Classification or regression |
| **Difficulty**      | Hard to ensure \( $\sum_x P(x) = 1$ \) | Easier to optimize |
| **Examples**       | GANs, VAEs, Diffusion Models | SVM, Logistic Regression, Neural Nets |
| **Output**         | Generates new samples | Predicts labels or values |
| **Computation**    | Computationally expensive | More efficient in training |

---

### **Key Takeaways**
- **Discriminative models** focus on prediction, while **generative models** focus on modeling the data distribution.
- **Generative models** are essential for applications like image synthesis, speech generation, and drug discovery.
- **Challenges** in generative modeling include density estimation and efficient sampling.
- **Recent advances** like VAEs, GANs, and diffusion models have improved generative modeling significantly.

---
