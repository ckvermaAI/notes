# Auto-Regressive Models

## Recap on Generative Models

### Variational Autoencoder (VAE)
- Structure: **Image → Latent Space → Image**
- Latent space is **encouraged to be Gaussian** using loss function.

### Generative Adversarial Network (GAN)
- Structure: **Gaussian → Image**
- Loss function **compares distributions** rather than explicit likelihood.

### Flow-Based Models
- Structure: **Gaussian ↔ Image**
- Requires **invertible architectures** for exact likelihood computation.

---

## Auto-Regressive Models

### What are Auto-Regressive Models?
- A class of probabilistic models that **factorize the joint probability** of data as a product of conditional distributions.
- Each data point is modeled as a **sequential generation** process.

### Features of Auto-Regressive Models
- **Fast training:** Each step directly models conditional probabilities.
- **Slow sampling/inference:** Each element must be generated sequentially.

### Examples
- **WaveNet**: Used for **audio generation**.
- **PixelCNN**: Used for **image generation**.

---

## Issues with Auto-Regressive Models
- **Difficult to learn long-range dependencies**: Limited receptive field in sequential modeling.
- **Slow generation**: Since each step requires computation of previous elements, **lookahead perspective** is required for efficient sampling.

---

## Compression and Auto-Regressive Models
- **Auto-regressive models provide optimal lossless compression**.
- Achieves **compression close to theoretical limits** (within 1 bit of entropy).

---

## Arithmetic Coding (Lossless Compression)

- Compression formula: **$-\log_2 P(x) + 1$ bits**.
- **Steps:**
  1. Sort **x** lexicographically.
  2. Compute CDF($P(X < x)$)
  3. Split the range **\[0,1\]** into intervals based on probabilities.
  4. Encode **x** using an index in the range.

### Arithmetic Coding in Practice
- Directly computing **P(X < x)** is difficult.
- However, **factorizing it using auto-regressive models** simplifies it:
  - $P(x) = \prod_{t=1}^{T} P(x_t | x_1, ..., x_{t-1})$
  - $P(X \leq x) = \prod_{t=1}^{T} P(X_t \leq x_t | x_1, ..., x_{t-1})$
- **Auto-regressive models lead to adaptive arithmetic coding**, making them powerful for compression.
