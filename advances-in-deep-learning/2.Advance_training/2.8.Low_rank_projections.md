# Low-Rank Projections Lecture Summary

## A) QLoRA Disadvantages

### 1. Fine-tuning Only
QLoRA is restricted to fine-tuning since it relies on a LoRA adapter that modifies only specific parts of the model. The base model remains unchanged, making it unsuitable for training models from scratch.

### 2. Task Dependence
- The effectiveness of QLoRA is highly dependent on the task.
- Some tasks require large modifications to the model, which necessitate a high-rank LoRA adapter.
- Other tasks require minimal adjustments, allowing a low-rank adapter.

### 3. Memory Efficiency
- Memory-wise, QLoRA is nearly optimal for fine-tuning.
- However, it does not help in reducing memory for full-model training.

## B) Backpropagation, Activations, and Memory Requirements

### 1. Forward Pass
- The input \( X \) is transformed through each layer.
- Some intermediate transformations (activations) are stored for use in the backward pass.

### 2. Backward Pass
- Computes gradients using stored activations.
- Linear layer gradients are computed as the outer product of the input and the backpropagated signal.
- Non-linear layers require their inputs to compute gradients.

### 3. Memory Allocation and Deallocation
- During backpropagation, memory is allocated for gradients and deallocated for activations.
- PyTorch automatically frees activations once they are no longer needed, preventing recomputation.
- Peak memory usage occurs just before `optimizer.step()`, where activations, gradients, and optimizer states (e.g., momentum terms) coexist.

## C) Memory-Efficient Backpropagation

### 1. Gradient Discarding
- Instead of retaining all gradients, optimizer updates are performed immediately after computing each gradient.
- Reduces peak memory usage by eliminating the need to store all gradients at once.

### 2. Advantages
- Enables training larger models on memory-constrained GPUs.
- Reduces redundant memory consumption for gradients.

### 3. Disadvantages
- Limited to single-GPU training.
- Incompatible with gradient accumulation.
- Requires modifying the optimizer to update parameters immediately.

## D) Gradients as Low-Rank Matrices

- The gradient of a linear layer is computed as:
  \[ $\nabla W = y_{in} \otimes y_{out}$ \]
  where \( $y_{in}$ \) is the input and \( $y_{out}$ \) is the backpropagated gradient.
- Since each sample contributes a rank-one update, the sum of these updates remains low-rank in practice.
- This property is especially true for transformers and MLPs but may not hold for convolutional networks.

## E) GaLore (Gradient Low-Rank Projection)

### 1. Key Idea
- Instead of storing full gradients, GaLore projects them into a low-rank subspace, significantly reducing memory usage.

### 2. Implementation Steps
1. Compute the full gradient.
2. Perform Singular Value Decomposition (SVD) to identify the best low-rank approximation.
3. Store and update weights in this reduced space.
4. Reproject back to full rank after updates.

### 3. Benefits
- Optimizer state remains significantly smaller.
- Enables training large models on consumer-grade GPUs (e.g., 24GB VRAM).

### 4. Drawbacks
- SVD computation is expensive and must be performed every 200 steps.
- Works only on a single GPU.
- Momentum terms may become misaligned when the low-rank subspace changes.

## F) Q-GaLore (Quantized GaLore)

### 1. Combining Quantization with Low-Rank Updates
- Quantizes both weights and projected gradients, reducing memory even further.
- Uses stochastic rounding to ensure small gradients still contribute to weight updates.

### 2. Advantages
- Reduces memory requirements below 16GB for large models.
- Requires fewer SVD updates (every 400 steps instead of 200).

### 3. Challenges
- Ensuring gradient updates remain effective despite quantization noise.
- Balancing projection accuracy and quantization efficiency.

## G) Discussion and Future Directions

### 1. QLoRA vs. GaLore
| Feature | QLoRA | GaLore |
|---------|-------|--------|
| Fine-tuning only | ✅ | ❌ |
| Full model training | ❌ | ✅ |
| Memory efficiency | ✅ | ✅✅ |
| Multi-GPU compatibility | ✅ | ❌ |
| Stability | ✅ | ⚠️ (less stable) |
| Computational cost | ✅ | ⚠️ (expensive SVD) |

### 2. Potential Improvements
- Future methods may combine QLoRA’s quantization with GaLore’s gradient compression to enable efficient multi-GPU training.
- Better techniques for updating quantized weights and handling momentum terms in low-rank projections.

---
This lecture provides an in-depth exploration of low-rank projections, memory-efficient training, and advanced optimization techniques, highlighting current trade-offs and future research directions.

