# Tool Use in LLMs

This lecture explores how large language models (LLMs) can be taught to use tools to enhance their capabilities, addressing limitations in handling tasks like time queries and math without external information or computation. It covers the challenges of LLMs relying on pre-training and fine-tuning data, introduces techniques like code interpretation and tool calls (e.g., ToolFormer, AnyTool), and details their training and inference processes. The lecture uses LLaMA 3.1 as an example and highlights security and scalability considerations as of March 17, 2025.

---

## Introduction and Context

- **Background**: Builds on prior segments covering pre-training (absorbing world knowledge), instruction tuning (enabling chat-style dialog), and RLHF (reinforcing good outputs).
- **Motivation**: LLMs struggle with tasks requiring real-time data (e.g., current time) or complex computation (e.g., math), often hallucinating answers when forced to respond.

---

## Limitations of LLMs Without Tools

- **Example 1: Time Query**:
  - **Test**: Asking LLaMA 3.1 8B "What time is it?" with a constraint to answer in numbers.
  - **Result**: Produces arbitrary times (e.g., same time repeatedly) due to lack of real-time awareness, reflecting memorized training data.
  - **Alternative Response**: Without the constraint, it refuses, suggesting the user check a clock or search online, likely due to fine-tuning with refusal prompts.
  - **Circumvention**: Forcing numeric answers bypasses refusal, exploiting instruction-following fine-tuning.
- **Example 2: Contextual Inconsistencies**:
  - **Test**: Asking in one conversation "Is it morning?", "Is it night?", "Is it noon?", "Is it afternoon?" with one-word answers.
  - **Result**: Produces inconsistent answers (e.g., "Yes" to all), unable to reason about mutual exclusivity due to lack of real-time context.
- **Example 3: Math Limitations**:
  - **Test**: Previous segment showed \( 54,321 + 12,345 \) often miscalculated (e.g., "66,676" or "66,566").
  - **Reason**: Token-space math is challenging, especially without carry mechanisms, and short-answer constraints limit reasoning space.
  - **Additional Insight**: LLMs perform better with scratch space (e.g., multi-token outputs), though this is unrelated to tool use.
- **Core Issue**: LLMs lack access to external information or computation, leading to hallucination when forced to answer.

---

## Enabling Tool Use with Code Interpretation

- **Concept**: LLMs can generate Python code to address queries, leveraging pre-training and fine-tuning data rich in coding examples.
- **Example 1: Time Query with Code**:
  - **Prompt**: "What time is it? Feel free to write some Python code to figure this out."
  - **Result**: LLaMA 3.1 generates Python code (e.g., `from datetime import datetime; print(datetime.now())`), but misinterprets the user’s intent, analyzing the code instead of using its output.
  - **Fix**: Requires a system prompt (e.g., `environment: IPython`) and a response format where the user feeds back the code’s result (e.g., "15:44, Sunday") for the model to continue.
- **Example 2: Math with Code**:
  - **Prompt**: "What is \( 54,321 + 12,345 \)? Feel free to write some Python code."
  - **Result**: Generates code (e.g., `print(54321 + 12345)`), but hallucinates if the result isn’t provided, showing the need for user feedback.
- **Training Basis**:
  - Pre-training includes coding tutorials and examples; fine-tuning and preference data reinforce code generation.
  - LLaMA 3.1 uses a special IPython chat template and header to integrate code interpreter responses, trained with manual dialogs of requests, code, results, and follow-ups.
- **Limitations**:
  - Imperfect execution due to formatting issues or misaligned expectations.
  - Security risks from arbitrary code (e.g., GPT models revealing server IPs without safeguards).

---

## Security and Scalability Challenges

- **Security Concerns**:
  - **Risk**: Running untrusted code (e.g., GPT tool calls revealing machine IPs) poses security threats.
  - **Solution**: Use a Docker container for the Python interpreter, ideally with internet disabled, though this limits external data access.
- **Scalability Issue**:
  - Python’s broad library set is insecure and overwhelming for LLMs to navigate, necessitating a more controlled approach.

---

## Tool Calls: A Controlled Alternative

- **Concept**: Instead of raw Python, LLMs use predefined, limited tool calls (e.g., functions) to gather information or perform tasks.
- **Examples of Tools**:
  - ToolFormer (2023): Calculator, Q&A, translation, Wikipedia search, date (calendar).
  - General Tools: Date, calculator, search, calendar, file reading.
- **Inference Process**:
  - **Standard**: LLM generates a token, which, if a tool call (e.g., "date"), triggers tool execution; the result is fed back as tokens for continued generation.
  - **OpenAI API**: Supports multiple tool calls with aggregated responses.
  - **Open Models (e.g., LLaMA)**: Typically one tool call per response, followed by a new call after feedback.
- **Training Process**:
  - **Data**: Long dialogs of user requests, tool calls, results, and LLM responses, with supervision only on tool calls and responses (masked for user/tool outputs).
  - **Shifted Input/Output**: Unlike standard training (outputs = inputs shifted by one), tool use introduces discrepancies (e.g., tool call output vs. tool call + result input), but this is accommodated during fine-tuning.

---

## ToolFormer: Data Construction for Tool Use

- **Overview**: ToolFormer (Schick et al., 2023) converts text datasets into tool-augmented datasets using in-context learning and filtering.
- **Steps**:
  1. **Load Dataset**: Example: "The president of the United States is Joe Biden" (from 2023 data).
  2. **In-Context Learning**: Teach LLM to insert tool calls using examples (e.g., "Coca-Cola or Coke is a carbonated soft drink" → `<API> QA: What other name is Coca-Cola known for? </API> coke`).
  3. **Construct N Prompts**: For an \( N \)-word sentence, insert a tool call (e.g., `<API> QA: Who is the president of the United States? </API>`) after every word \( i \), letting the LLM complete without answers.
  4. **Keep Useful Examples**: Compare three outputs:
     - \( L(\epsilon) \): Original sentence.
     - \( L(Q, \epsilon) \): Sentence with tool call (e.g., "The president of the United States `<API> QA: Who is the president? </API>`").
     - \( L(Q, a) \): Sentence with tool call and answer (e.g., "... `<API> QA: Who is the president? </API> Joe Biden`").
     - Filter by negative log likelihood: Keep examples where \( L(Q, a) + \tau \leq \min(L(\epsilon), L(Q)) \), indicating the tool call improves prediction.
- **Outcome**: Produces a dataset with interleaved text and tool calls (e.g., `<API> QA: Who is the president? </API> Joe Biden`), trained on five tools, improving math and Q&A performance over GPT and LLaMA benchmarks.
- **Advantage**: Automates data creation, avoiding manual labeling.

---

## AnyTool: Zero-Shot Tool Use with Scalability

- **Challenge**: Fixed tool sets (e.g., ToolFormer’s five tools) require retraining for new tools, which is impractical.
- **Solution**: AnyTool (2024) introduces a hierarchical, self-reflective system for 16K+ APIs.
- **Structure**:
  - **4 Levels of Agents**:
    - **Meta-Agent**: Oversees the process.
    - **Category-Agent**: Identifies relevant tool categories (e.g., music, sports).
    - **Tool-Agent**: Selects specific tools within categories.
    - **LLM Solver**: Executes the solution.
  - **Process**:
    - **API Pool (16K+ APIs)**: Large set of potential tools.
    - **API-Retriever**: Uses meta-tools to explore categories and tools (e.g., "What apps can I use?" → "Music app" → "Specific function").
    - **Solver**: Calls the function, gets results.
    - **Self-Reflection**: If unsolved, retries with adjusted strategy.
- **Features**:
  - Tools described in context (e.g., JSON format like OpenAI’s or LLaMA’s variant), including distractors.
  - Generalizes zero-shot to new tools via retrieval, avoiding exhaustive context inclusion.
- **Advantage**: Scales to thousands of tools without retraining, using hierarchical exploration.

---

## Conclusion

- **Summary**: LLMs lack real-time data and math skills, often hallucinating when forced to respond. Code interpretation (e.g., LLaMA 3.1’s IPython template) and tool calls (e.g., ToolFormer, AnyTool) enable external computation and information retrieval. ToolFormer automates dataset creation with in-context learning and filtering, while AnyTool’s hierarchical system handles 16K+ APIs zero-shot. Security (e.g., Docker sandboxes) and scalability (beyond dozens of tools) are critical considerations.
- **Context (March 17, 2025)**: Tool use is a growing field, with LLaMA 3.1 and GPT models showcasing practical implementations, and papers like AnyTool pushing scalability limits.

---

### Additional Context
- **Historical Note**: ToolFormer (2023) pioneered automated tool-augmented datasets, while AnyTool (2024) advanced zero-shot capabilities, reflecting rapid progress.
- **Applications**: Enhances LLMs in virtual assistants, data analysis, and system control (e.g., file management).
- **Research Trends**: Focus on secure execution (e.g., sandboxing) and large-scale tool integration (e.g., 16K APIs) is intensifying as LLM use expands.

This summary includes all transcript points, integrates image details, and adds context on trends and applications.